{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import dask.dataframe as pd  # Consumes over 200G memory and run over 1 hour, worse than pandas\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import dask.bag as db\n",
    "from dask.diagnostics import ProgressBar\n",
    "import gc\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hardware:** n1-highmem-32, 32 vCPUs, 208 GB memory, 1TB SSD, 4 x NVIDIA Tesla V100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert JSON to HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/data/trade'\n",
    "OUTPUT_DIR = '/data/hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ValueError: Value is too big, Huobi.Spot.EOS_BTC.2020-05-06.json\n",
    "# https://stackoverflow.com/a/61733123/381712\n",
    "import json\n",
    "pd.io.json._json.loads = lambda s, *a, **kw: json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dates(exchange:str, market_type:str, pair:str, data_dir:str, output_dir: str)->None:\n",
    "    json_files = glob.glob(os.path.join(data_dir, f'**/{exchange}.{market_type}.{pair}.*.json'), recursive=True)\n",
    "    json_files = sorted(json_files)\n",
    "    pd.io.json._json.loads = lambda s, *a, **kw: json.loads(s)  # ValueError: Value is too big\n",
    "    dfs = [pd.read_json(file, lines=True, dtype=False).drop(\n",
    "        columns=['rawPair', 'channel', 'channelType', 'raw']) for file in json_files]\n",
    "    df = pd.concat(dfs)\n",
    "    df.to_hdf(\n",
    "        os.path.join(output_dir, f'{exchange}.{market_type}.{pair}.hdf5'),\n",
    "        key=f'{exchange}__{market_type}__{pair}',\n",
    "        mode='w',\n",
    "        complevel=9)\n",
    "    del df\n",
    "    del dfs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge_dates('OKEx', 'Swap', 'XMR_USDT', DATA_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_multi(market_type:str, input_dir:str, output_dir:str)->None:\n",
    "    assert market_type != 'Futures'\n",
    "    json_files = glob.glob(os.path.join(input_dir, f'**/*.{market_type}.*.json'), recursive=True)\n",
    "    # exchange -> pairs\n",
    "    exchange_pairs = {}\n",
    "    for file in json_files:\n",
    "        filename = os.path.basename(file)\n",
    "        arr = filename.split('.')\n",
    "        exchange = arr[0]\n",
    "        assert market_type == arr[1]\n",
    "        pair = arr[2]\n",
    "        if exchange not in exchange_pairs:\n",
    "            exchange_pairs[exchange] = []\n",
    "        exchange_pairs[exchange].append(pair)\n",
    "    # deduplication\n",
    "    for exchange in exchange_pairs:\n",
    "        exchange_pairs[exchange] = sorted(list(dict.fromkeys(exchange_pairs[exchange])))\n",
    "    # flatten\n",
    "    exchange_pair_arr = []\n",
    "    for exchange in exchange_pairs:\n",
    "        pairs = exchange_pairs[exchange]\n",
    "        for pair in pairs:\n",
    "            exchange_pair_arr.append((exchange, pair))\n",
    "    with ProgressBar():\n",
    "        db.from_sequence(exchange_pair_arr).map(\n",
    "            lambda item: merge_dates(item[0], market_type, item[1], input_dir, output_dir)).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 12min 51.0s\n"
     ]
    }
   ],
   "source": [
    "merge_multi('Swap', DATA_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 13min 26.3s\n"
     ]
    }
   ],
   "source": [
    "merge_multi('Spot', DATA_DIR, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
